{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDPM Point Cloud Generation\n",
    "\n",
    "**使用方法:**\n",
    "1. 确保选择 GPU: Runtime → Change runtime type → GPU (T4)\n",
    "2. 运行 Setup cell，等待自动重启\n",
    "3. 重启后，从 Section 2 开始运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup (自动重启)\n",
    "import os\n",
    "\n",
    "SETUP_FLAG = '/content/.vdpm_ready_v2'\n",
    "\n",
    "if os.path.exists(SETUP_FLAG):\n",
    "    print(\"✓ 已完成安装，请从 Section 2 继续运行\")\n",
    "else:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step 1: Clone VDPM\")\n",
    "    print(\"=\" * 50)\n",
    "    !rm -rf /content/vdpm\n",
    "    !git clone --depth 1 https://github.com/eldar/vdpm.git /content/vdpm\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Step 2: Fix NumPy\")\n",
    "    print(\"=\" * 50)\n",
    "    !pip uninstall -y numpy\n",
    "    !pip install numpy==1.26.4\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Step 3: Install VGGT\")\n",
    "    print(\"=\" * 50)\n",
    "    !pip install git+https://github.com/facebookresearch/vggt.git@44b3afb\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Step 4: Install other deps\")\n",
    "    print(\"=\" * 50)\n",
    "    !pip install roma omegaconf einops jaxtyping\n",
    "    \n",
    "    # 验证安装\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Verifying installation...\")\n",
    "    print(\"=\" * 50)\n",
    "    !python -c \"import vggt; print('vggt OK')\"\n",
    "    !python -c \"import omegaconf; print('omegaconf OK')\"\n",
    "    \n",
    "    # 标记完成\n",
    "    !touch {SETUP_FLAG}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"✓ 安装完成！正在重启...\")\n",
    "    print(\"重启后请从 Section 2 继续\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 强制重启\n",
    "    os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 加载模型 (重启后从这里开始)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir('/content/vdpm')\n",
    "sys.path.insert(0, '/content/vdpm')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 验证 vggt\n",
    "import vggt\n",
    "print(\"vggt: OK\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from dpm.model import VDPM\n",
    "\n",
    "# 配置\n",
    "cfg = OmegaConf.create({\n",
    "    'model': {'name': 'dpm-video', 'pretrained': None, 'decoder_depth': 4}\n",
    "})\n",
    "\n",
    "# 加载模型\n",
    "print(\"加载模型中...\")\n",
    "model = VDPM(cfg).to(device)\n",
    "\n",
    "# 下载权重\n",
    "url = \"https://huggingface.co/edgarsucar/vdpm/resolve/main/model.pt\"\n",
    "weights = torch.hub.load_state_dict_from_url(url, file_name=\"vdpm_model.pt\")\n",
    "model.load_state_dict(weights, strict=True)\n",
    "model.eval()\n",
    "\n",
    "print(\"✓ 模型加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "\n",
    "def extract_and_save_frames(video_path, output_dir, sample_hz=1.0):\n",
    "    \"\"\"从视频提取帧并保存为图片\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    interval = max(int(fps / sample_hz), 1)\n",
    "    \n",
    "    paths = []\n",
    "    count = 0\n",
    "    frame_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % interval == 0:\n",
    "            path = output_dir / f\"{frame_idx:04d}.png\"\n",
    "            cv2.imwrite(str(path), frame)\n",
    "            paths.append(str(path))\n",
    "            frame_idx += 1\n",
    "        count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"提取了 {len(paths)} 帧\")\n",
    "    return sorted(paths)\n",
    "\n",
    "\n",
    "def run_vdpm(video_path, output_dir, ref_frame=0):\n",
    "    \"\"\"运行 VDPM 生成点云\n",
    "    \n",
    "    Args:\n",
    "        video_path: 视频路径\n",
    "        output_dir: 输出目录\n",
    "        ref_frame: 参考帧索引 (点云基于此帧的视角)\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 提取帧到临时目录\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        frame_paths = extract_and_save_frames(video_path, tmp)\n",
    "        \n",
    "        # 使用官方预处理函数\n",
    "        images = load_and_preprocess_images(frame_paths).to(device)\n",
    "        print(f\"输入形状: {images.shape}\")\n",
    "    \n",
    "    # 推理\n",
    "    print(\"运行推理...\")\n",
    "    with torch.no_grad():\n",
    "        result = model.inference(None, images=images.unsqueeze(0))\n",
    "    \n",
    "    # 提取点云 (参考 gradio_demo.py 的处理方式)\n",
    "    # pts3d 形状: [batch, num_target_frames, H, W, 3]\n",
    "    # conf 形状: [batch, num_target_frames, H, W]\n",
    "    pointmaps = result['pointmaps']\n",
    "    \n",
    "    # 收集所有帧的点云\n",
    "    pts_list = [pm['pts3d'].detach().cpu().numpy() for pm in pointmaps]\n",
    "    conf_list = [pm['conf'].detach().cpu().numpy() for pm in pointmaps]\n",
    "    \n",
    "    # 拼接: [num_frames, num_target_frames, H, W, 3]\n",
    "    world_points = np.concatenate(pts_list, axis=0)\n",
    "    world_conf = np.concatenate(conf_list, axis=0)\n",
    "    \n",
    "    print(f\"world_points shape: {world_points.shape}\")\n",
    "    print(f\"world_conf shape: {world_conf.shape}\")\n",
    "    \n",
    "    num_frames = world_points.shape[0]\n",
    "    \n",
    "    # 使用参考帧的视角，获取每一帧的点云\n",
    "    # world_points[:, ref_frame, :, :, :] 表示从 ref_frame 视角看的所有帧的点云\n",
    "    all_pts = []\n",
    "    all_conf = []\n",
    "    \n",
    "    for t in range(num_frames):\n",
    "        # 从参考帧视角看第 t 帧的点云\n",
    "        pts = world_points[t, ref_frame, :, :, :].reshape(-1, 3)\n",
    "        conf = world_conf[t, ref_frame, :, :].reshape(-1)\n",
    "        \n",
    "        np.savez(output_dir / f\"frame_{t:03d}.npz\", points=pts, conf=conf)\n",
    "        all_pts.append(pts)\n",
    "        all_conf.append(conf)\n",
    "        print(f\"  帧 {t}: {len(pts)} 个点\")\n",
    "    \n",
    "    # 保存序列\n",
    "    np.savez(\n",
    "        output_dir / \"sequence.npz\",\n",
    "        points=np.stack(all_pts),\n",
    "        conf=np.stack(all_conf)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ 保存到 {output_dir}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## 4. 处理 VLM4D 测试视频 (10 个 GPT-5 mini 答错的题目)\n\n点云将保存到 `/content/vdpm/vlm4d_pointclouds/{video_name}/sequence.npz`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import requests\n\n# 10 个 VLM4D 视频 URL\nVLM4D_VIDEOS = [\n    (\"baseball\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/baseball.mp4\"),\n    (\"basketball-game\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/basketball-game.mp4\"),\n    (\"bear\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/bear.mp4\"),\n    (\"bike-packing\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/bike-packing.mp4\"),\n    (\"blackswan\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/blackswan.mp4\"),\n    (\"bmx-bumps\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/bmx-bumps.mp4\"),\n    (\"bmx-rider\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/bmx-rider.mp4\"),\n    (\"boat\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/boat.mp4\"),\n    (\"breakdance\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/breakdance.mp4\"),\n    (\"breakdance-flare\", \"https://huggingface.co/datasets/shijiezhou/VLM4D/resolve/main/videos_real/davis/breakdance-flare.mp4\"),\n]\n\n# 下载视频\nVIDEO_DIR = Path(\"/content/vdpm/vlm4d_videos\")\nVIDEO_DIR.mkdir(parents=True, exist_ok=True)\n\nfor name, url in VLM4D_VIDEOS:\n    video_path = VIDEO_DIR / f\"{name}.mp4\"\n    if video_path.exists():\n        print(f\"✓ 已存在: {name}.mp4\")\n    else:\n        print(f\"下载: {name}.mp4 ...\", end=\" \")\n        resp = requests.get(url)\n        video_path.write_bytes(resp.content)\n        print(\"完成\")\n\nprint(f\"\\n✓ 所有视频已下载到 {VIDEO_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 批量处理 VLM4D 视频\nimport time\n\nPOINTCLOUD_DIR = Path(\"/content/vdpm/vlm4d_pointclouds\")\nPOINTCLOUD_DIR.mkdir(parents=True, exist_ok=True)\n\nresults = {}\n\nfor name, url in VLM4D_VIDEOS:\n    video_path = VIDEO_DIR / f\"{name}.mp4\"\n    output_dir = POINTCLOUD_DIR / name\n\n    print(f\"\\n{'='*50}\")\n    print(f\"处理: {name}\")\n    print(f\"{'='*50}\")\n\n    # 检查是否已存在\n    if (output_dir / \"sequence.npz\").exists():\n        print(f\"✓ 点云已存在，跳过\")\n        results[name] = \"✓ 已存在\"\n        continue\n\n    start = time.time()\n    try:\n        run_vdpm(str(video_path), str(output_dir))\n        elapsed = time.time() - start\n        results[name] = f\"✓ 成功 ({elapsed:.1f}s)\"\n    except Exception as e:\n        results[name] = f\"✗ 失败: {e}\"\n\n    # 清理显存\n    torch.cuda.empty_cache()\n\nprint(f\"\\n{'='*50}\")\nprint(\"处理结果汇总:\")\nprint(f\"{'='*50}\")\nfor name, status in results.items():\n    print(f\"  {name}: {status}\")\n\nprint(f\"\\n点云保存位置: {POINTCLOUD_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## 5. 检查 VLM4D 点云结果"
  },
  {
   "cell_type": "code",
   "source": "# 检查 VLM4D 点云结果\nprint(\"生成的点云:\")\nfor name, _ in VLM4D_VIDEOS:\n    npz_path = POINTCLOUD_DIR / name / \"sequence.npz\"\n    if npz_path.exists():\n        data = np.load(npz_path)\n        print(f\"  ✓ {name}: points={data['points'].shape}, conf={data['conf'].shape}\")\n    else:\n        print(f\"  ✗ {name}: 缺失\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>## 6. 下载 VLM4D 点云\n\n下载后解压到 `test_vdpm_gpt5mini_vlm4d.ipynb` 所在目录的 `vlm4d_pointclouds/` 文件夹",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!cd /content/vdpm && zip -r /content/vlm4d_pointclouds.zip vlm4d_pointclouds/\nfrom google.colab import files\nfiles.download(\"/content/vlm4d_pointclouds.zip\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}