{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 mini 在 VLM4D 数据集上的测试\n",
    "\n",
    "这个 notebook 测试 OpenAI 的 GPT-5 mini 模型在 VLM4D 数据集上的表现。\n",
    "\n",
    "**数据集:**\n",
    "- `real_mc.json`: 真实视频数据 (1371 个问题)\n",
    "- `synthetic_mc.json`: 合成视频数据\n",
    "\n",
    "**问题类型:** 多项选择题，关于视频中物体的运动方向、轨迹等\n",
    "\n",
    "**参数设置:** 与 VLM4D 官方保持一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果在 Colab 运行，取消注释下面的行\n",
    "# !pip install openai aiolimiter tqdm python-dotenv opencv-python pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport asyncio\nimport base64\nimport hashlib\nimport cv2\nimport requests\nimport random\nimport numpy as np\nfrom string import Template\nfrom tqdm.asyncio import tqdm_asyncio\nfrom tqdm import tqdm\nimport aiolimiter\nfrom pydantic import BaseModel\nfrom openai import AsyncOpenAI, OpenAIError\n\n# 配置\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # 或者直接填入你的 API key\n# OPENAI_API_KEY = \"sk-xxx\"  # 取消注释并填入你的 key\n\nif not OPENAI_API_KEY:\n    raise ValueError(\"请设置 OPENAI_API_KEY 环境变量或直接在代码中填入\")\n\nprint(f\"API Key 已配置: {OPENAI_API_KEY[:10]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 常量和 Prompt 模板\n",
    "\n",
    "与 VLM4D 官方 `utils/constant.py` 保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常量 (来自 VLM4D utils/constant.py)\n",
    "MAX_TOKENS = 1024\n",
    "GENERATION_TEMPERATURE = 1.0\n",
    "\n",
    "# Prompt 模板 (来自 VLM4D utils/constant.py)\n",
    "MULTI_CHOICE_COT_PROMPT = Template(\"\"\"\n",
    "Question: $question\n",
    "$optionized_str\n",
    "\n",
    "Answer the given multiple-choice question step by step. Begin by explaining your reasoning process clearly. In the last sentence of your response, you must conclude by stating the final answer using the following format: 'Therefore, the final answer is: $$LETTER' (without quotes), where $$LETTER must be only one of the options (A or B or C or D). Think step by step before answering.\"\"\")\n",
    "\n",
    "MULTI_CHOICE_DO_PROMPT = Template(\"\"\"\n",
    "Question: $question\n",
    "$optionized_str\n",
    "\n",
    "Do not generate any intermediate reasoning process. Answer directly with the option letter from the given choices.\n",
    "\"\"\")\n",
    "\n",
    "# 评估用的 prompt (来自 VLM4D utils/eval_utils.py)\n",
    "EVAL_INSTRUCTION = \"\"\"Your task is to evaluate whether the model's final answer is correct by comparing it to the ground-truth answer provided for the given question.\n",
    "\n",
    "You should first extract the final answer from the model's response, and then compare the extracted answer with the choice that matches the ground-truth answer to determine its correctness.\n",
    "Output your response in the following structured format:\n",
    "{\n",
    "    \"extracted_answer\": // str value \"A\" \"B\" \"C\" \"D\", followed by a colon and the corresponding answer text, e.g., \"A: Answer A text\". If the model's response does not contain a valid choice and reasoning, then \"No Valid Answer\".\n",
    "    \"correct\": // boolean value, True if the extracted answer matches the ground-truth answer (correct choice), False otherwise (\"No Valid Answer\" is also considered False).\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompt 模板已加载 (与 VLM4D 官方一致)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 工具函数\n",
    "\n",
    "与 VLM4D 官方 `utils/video_process.py` 保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频下载和处理 (来自 VLM4D utils/video_process.py)\n",
    "def download_video(video_url, video_tmp_dir=\"video_cache\"):\n",
    "    \"\"\"下载视频到本地缓存\"\"\"\n",
    "    video_id = hashlib.md5(video_url.encode()).hexdigest()\n",
    "    video_subdir = os.path.join(video_tmp_dir, video_id)\n",
    "    os.makedirs(video_subdir, exist_ok=True)\n",
    "    \n",
    "    video_path = os.path.join(video_subdir, \"video.mp4\")\n",
    "    if not os.path.exists(video_path):\n",
    "        with open(video_path, \"wb\") as f:\n",
    "            response = requests.get(video_url)\n",
    "            f.write(response.content)\n",
    "    \n",
    "    return video_path, video_id\n",
    "\n",
    "\n",
    "def read_video(video_path, total_frames):\n",
    "    \"\"\"从视频中均匀采样帧并转为 base64 (与 VLM4D 官方一致)\"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "    \n",
    "    try:\n",
    "        base64_frames = []\n",
    "        while True:\n",
    "            success, frame = video.read()\n",
    "            if not success:\n",
    "                break\n",
    "            _, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            base64_frames.append(frame_base64)\n",
    "        \n",
    "        # 均匀采样 (与 VLM4D 官方一致)\n",
    "        random.seed(42)\n",
    "        if total_frames == 1:\n",
    "            selected_indices = [np.random.choice(range(len(base64_frames)))]\n",
    "        else:\n",
    "            selected_indices = np.linspace(0, len(base64_frames) - 1, total_frames, dtype=int)\n",
    "        \n",
    "        selected_base64_frames = [base64_frames[i] for i in selected_indices]\n",
    "        return selected_base64_frames\n",
    "    finally:\n",
    "        video.release()\n",
    "\n",
    "\n",
    "def prepare_base64frames(video_url, total_frames, video_tmp_dir=\"video_cache\"):\n",
    "    \"\"\"获取视频帧（带缓存）\"\"\"\n",
    "    video_path, video_id = download_video(video_url, video_tmp_dir)\n",
    "    \n",
    "    # 检查缓存\n",
    "    cache_dir = os.path.join(video_tmp_dir, video_id, f\"{total_frames}_frames\")\n",
    "    cache_file = os.path.join(cache_dir, \"base64frames.json\")\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # 读取帧\n",
    "    base64frames = read_video(video_path, total_frames)\n",
    "    \n",
    "    # 保存缓存\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    with open(cache_file, \"w\") as f:\n",
    "        json.dump(base64frames, f)\n",
    "    \n",
    "    return base64frames\n",
    "\n",
    "\n",
    "print(\"工具函数已加载 (与 VLM4D 官方一致)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 准备输入\n",
    "\n",
    "与 VLM4D 官方 `utils/prepare_input.py` 保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_text_input(query, prompt):\n",
    "    \"\"\"准备问答文本 (来自 VLM4D utils/prepare_input.py)\"\"\"\n",
    "    question_type = query[\"question_type\"]\n",
    "    \n",
    "    if question_type == \"multiple-choice\":\n",
    "        optionized_list = [f\"{key}: {value}\" for key, value in query['choices'].items()]\n",
    "        optionized_str = \"\\n\".join(optionized_list)\n",
    "        qa_text_prompt = prompt.substitute(question=query['question'], optionized_str=optionized_str)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid question type: {question_type}\")\n",
    "    \n",
    "    return {\"type\": \"text\", \"text\": qa_text_prompt}\n",
    "\n",
    "\n",
    "def prepare_multi_image_input(base64frames):\n",
    "    \"\"\"准备多图像输入 (来自 VLM4D utils/prepare_input.py)\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{frame}\"}\n",
    "        }\n",
    "        for frame in base64frames\n",
    "    ]\n",
    "\n",
    "\n",
    "def prepare_qa_inputs(queries, total_frames, prompt, video_tmp_dir=\"video_cache\"):\n",
    "    \"\"\"为所有问题准备消息 (来自 VLM4D utils/prepare_input.py)\"\"\"\n",
    "    messages = []\n",
    "    for query in tqdm(queries, desc=\"准备输入\"):\n",
    "        qa_text_message = prepare_qa_text_input(query, prompt)\n",
    "        \n",
    "        if total_frames >= 1:\n",
    "            base64frames = prepare_base64frames(query['video'], total_frames, video_tmp_dir)\n",
    "            vision_input = prepare_multi_image_input(base64frames)\n",
    "            prompt_message = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": vision_input + [qa_text_message],\n",
    "                }\n",
    "            ]\n",
    "        elif total_frames == 0:\n",
    "            prompt_message = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [qa_text_message],\n",
    "                }\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid total_frames: {total_frames}\")\n",
    "        \n",
    "        messages.append(prompt_message)\n",
    "    return messages\n",
    "\n",
    "\n",
    "print(\"输入准备函数已加载 (与 VLM4D 官方一致)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. OpenAI API 调用\n",
    "\n",
    "与 VLM4D 官方 `utils/api_utils.py` 保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "async def _throttled_openai_chat_completion_acreate(\n    client,\n    model,\n    messages,\n    temperature,\n    max_tokens,\n    top_p,\n    limiter,\n):\n    \"\"\"单次 API 调用（带重试）(来自 VLM4D utils/api_utils.py)\"\"\"\n    async with limiter:\n        for _ in range(10):\n            try:\n                return await client.chat.completions.create(\n                    model=model,\n                    messages=messages,\n                    temperature=temperature,\n                    max_completion_tokens=max_tokens,  # GPT-5 系列使用 max_completion_tokens\n                    top_p=top_p,\n                )\n            except Exception as e:\n                if \"rate_limit\" in str(e).lower():\n                    print(\"Rate limit exceeded, retrying...\")\n                    await asyncio.sleep(random.randint(10, 20))\n                elif \"bad_request\" in str(e).lower():\n                    print(f\"Bad request: {e}\")\n                    return None\n                else:\n                    print(f\"Error: {e}\")\n                    await asyncio.sleep(random.randint(5, 10))\n        return None\n\n\nasync def generate_from_openai_chat_completion(\n    client,\n    messages,\n    engine_name,\n    temperature=1.0,\n    max_tokens=512,\n    top_p=1.0,\n    requests_per_minute=150,\n):\n    \"\"\"批量调用 OpenAI API (来自 VLM4D utils/api_utils.py)\"\"\"\n    delay = 60.0 / requests_per_minute\n    limiter = aiolimiter.AsyncLimiter(1, delay)\n    \n    async_responses = [\n        _throttled_openai_chat_completion_acreate(\n            client,\n            model=engine_name,\n            messages=message,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            top_p=top_p,\n            limiter=limiter,\n        )\n        for message in messages\n    ]\n    \n    responses = await tqdm_asyncio.gather(*async_responses, desc=\"API 调用\")\n    \n    outputs = []\n    for response in responses:\n        try:\n            outputs.append(response.choices[0].message.content)\n        except Exception as e:\n            print(f\"Error extracting response: {e}\")\n            outputs.append(\"\")\n    \n    return outputs\n\n\nprint(\"API 调用函数已加载 (与 VLM4D 官方一致)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 评估函数\n",
    "\n",
    "与 VLM4D 官方 `utils/eval_utils.py` 保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationOutput(BaseModel):\n",
    "    extracted_answer: str\n",
    "    correct: bool\n",
    "\n",
    "\n",
    "def prepare_evaluation_message(example, response):\n",
    "    \"\"\"准备评估消息 (来自 VLM4D utils/eval_utils.py)\"\"\"\n",
    "    question_type = example[\"question_type\"]\n",
    "    \n",
    "    if question_type == \"multiple-choice\":\n",
    "        optionized_list = [f\"{key}: {value}\" for key, value in example['choices'].items()]\n",
    "        optionized_str = \"\\n\".join(optionized_list)\n",
    "        question_context = f\"Question: {example['question']}\\n\\nOptions:\\n{optionized_str}\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    gt_answer = f\"Ground Truth Answer: {example['answer']}\"\n",
    "    model_response = f\"Model Response to the Question: {response}\"\n",
    "    \n",
    "    user_prompt = f\"{question_context}\\n\\n{gt_answer}\\n\\n{model_response}\"\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": EVAL_INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "async def _throttled_eval_call(client, model, messages, limiter):\n",
    "    \"\"\"单次评估调用\"\"\"\n",
    "    async with limiter:\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                response = await client.beta.chat.completions.parse(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=1.0,\n",
    "                    max_tokens=1024,\n",
    "                    top_p=1.0,\n",
    "                    response_format=EvaluationOutput,\n",
    "                )\n",
    "                return response.choices[0].message.parsed\n",
    "            except Exception as e:\n",
    "                if \"rate_limit\" in str(e).lower():\n",
    "                    await asyncio.sleep(random.randint(10, 20))\n",
    "                else:\n",
    "                    print(f\"Eval error: {e}\")\n",
    "                    await asyncio.sleep(random.randint(5, 10))\n",
    "        return None\n",
    "\n",
    "\n",
    "async def get_acc_async(examples, client, eval_model=\"o4-mini\"):\n",
    "    \"\"\"评估所有响应 (来自 VLM4D utils/eval_utils.py)\"\"\"\n",
    "    evaluation_messages = [\n",
    "        prepare_evaluation_message(example, example['response'])\n",
    "        for example in examples\n",
    "    ]\n",
    "    \n",
    "    # 批量评估\n",
    "    delay = 60.0 / 1000  # 1000 requests per minute for eval\n",
    "    limiter = aiolimiter.AsyncLimiter(1, delay)\n",
    "    \n",
    "    tasks = [_throttled_eval_call(client, eval_model, msg, limiter) for msg in evaluation_messages]\n",
    "    outputs = await tqdm_asyncio.gather(*tasks, desc=\"评估中\")\n",
    "    \n",
    "    # 统计结果\n",
    "    count = 0\n",
    "    results = []\n",
    "    for example, output in zip(examples, outputs):\n",
    "        result = {\n",
    "            \"id\": example[\"id\"],\n",
    "            \"question\": example[\"question\"],\n",
    "            \"choices\": example[\"choices\"],\n",
    "            \"response\": example[\"response\"],\n",
    "            \"ground_truth_answer\": example[\"answer\"],\n",
    "        }\n",
    "        try:\n",
    "            result[\"extracted_answer\"] = output.extracted_answer\n",
    "            result[\"correct\"] = output.correct\n",
    "        except Exception as e:\n",
    "            result[\"extracted_answer\"] = \"\"\n",
    "            result[\"correct\"] = False\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        results.append(result)\n",
    "        count += result[\"correct\"]\n",
    "    \n",
    "    return count / len(examples), results\n",
    "\n",
    "\n",
    "print(\"评估函数已加载 (与 VLM4D 官方一致)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径（根据你的环境调整）\n",
    "# 本地运行\n",
    "DATA_DIR = \"../VLM4D-main/data\"\n",
    "\n",
    "# Colab 运行时取消注释下面的行\n",
    "# !git clone https://github.com/ShijieZhou-UCLA/VLM4D.git\n",
    "# DATA_DIR = \"VLM4D/data\"\n",
    "\n",
    "# 加载数据\n",
    "real_mc_path = os.path.join(DATA_DIR, \"real_mc.json\")\n",
    "synthetic_mc_path = os.path.join(DATA_DIR, \"synthetic_mc.json\")\n",
    "\n",
    "with open(real_mc_path, \"r\") as f:\n",
    "    real_mc_data = json.load(f)\n",
    "\n",
    "with open(synthetic_mc_path, \"r\") as f:\n",
    "    synthetic_mc_data = json.load(f)\n",
    "\n",
    "print(f\"Real MC 数据: {len(real_mc_data)} 个问题\")\n",
    "print(f\"Synthetic MC 数据: {len(synthetic_mc_data)} 个问题\")\n",
    "\n",
    "# 查看示例\n",
    "print(\"\\n示例问题:\")\n",
    "print(json.dumps(real_mc_data[1], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 运行测试\n",
    "\n",
    "参数与 VLM4D 官方脚本一致:\n",
    "- 模型: `gpt-5-mini` (GPT-5 mini)\n",
    "- 帧数: 32 (与 gpt-4o 一致)\n",
    "- Prompt: COT 或 direct-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 (与 VLM4D 官方 run_api_models.sh 一致)\n",
    "MODEL_NAME = \"gpt-5-mini\"  # GPT-5 mini 模型 ID\n",
    "TOTAL_FRAMES = 32  # 与 gpt-4o 保持一致\n",
    "PROMPT_TYPE = \"cot\"  # \"cot\" 或 \"direct-output\"\n",
    "MAX_SAMPLES = -1  # 测试样本数，-1 为全部\n",
    "\n",
    "# 选择 prompt 模板\n",
    "prompt_template = MULTI_CHOICE_COT_PROMPT if PROMPT_TYPE == \"cot\" else MULTI_CHOICE_DO_PROMPT\n",
    "\n",
    "# 选择数据子集\n",
    "test_data = real_mc_data[:MAX_SAMPLES] if MAX_SAMPLES > 0 else real_mc_data\n",
    "\n",
    "print(f\"配置:\")\n",
    "print(f\"  模型: {MODEL_NAME}\")\n",
    "print(f\"  帧数: {TOTAL_FRAMES}\")\n",
    "print(f\"  Prompt: {PROMPT_TYPE}\")\n",
    "print(f\"  测试样本: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载视频并准备消息\n",
    "print(\"准备输入消息 (下载视频并提取帧)...\")\n",
    "all_messages = prepare_qa_inputs(test_data, TOTAL_FRAMES, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 API (与 VLM4D 官方 model_inference/azure_gpt.py 一致)\n",
    "print(\"调用 OpenAI API...\")\n",
    "client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# 计算请求速率 (与 VLM4D 官方一致)\n",
    "base_rate = 100  # 默认 base rate\n",
    "requests_per_minute = int(base_rate / (TOTAL_FRAMES ** 0.5))\n",
    "print(f\"请求速率: {requests_per_minute}/min\")\n",
    "\n",
    "responses = await generate_from_openai_chat_completion(\n",
    "    client=client,\n",
    "    messages=all_messages,\n",
    "    engine_name=MODEL_NAME,\n",
    "    temperature=GENERATION_TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    top_p=1.0,\n",
    "    requests_per_minute=requests_per_minute\n",
    ")\n",
    "\n",
    "print(f\"\\n获得 {len(responses)} 个响应\")\n",
    "\n",
    "# 将响应添加到数据中\n",
    "for query, response in zip(test_data, responses):\n",
    "    query[\"response\"] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看部分响应\n",
    "print(\"示例响应:\")\n",
    "for i in range(min(3, len(responses))):\n",
    "    print(f\"\\n--- 问题 {i+1} ---\")\n",
    "    print(f\"Q: {test_data[i]['question']}\")\n",
    "    print(f\"选项: {test_data[i]['choices']}\")\n",
    "    print(f\"正确答案: {test_data[i]['answer']}\")\n",
    "    resp = responses[i] if responses[i] else \"(无响应)\"\n",
    "    print(f\"模型回答: {resp[:500]}...\" if len(resp) > 500 else f\"模型回答: {resp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估 (与 VLM4D 官方 acc_evaluation.py 一致)\n",
    "print(\"评估响应...\")\n",
    "accuracy, results = await get_acc_async(test_data, client, eval_model=\"o4-mini\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"准确率: {accuracy:.2%} ({int(accuracy * len(results))}/{len(results)})\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看详细结果\n",
    "print(\"\\n详细结果 (前10个):\")\n",
    "for i, r in enumerate(results[:10]):\n",
    "    status = \"✓\" if r['correct'] else \"✗\"\n",
    "    print(f\"{status} Q{i+1}: {r['question'][:50]}...\")\n",
    "    print(f\"   正确: {r['ground_truth_answer']} | 提取: {r['extracted_answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果 (与 VLM4D 官方目录结构一致)\n",
    "output_dir = f\"../outputs/real_mc_{PROMPT_TYPE}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 保存模型输出\n",
    "output_file = os.path.join(output_dir, f\"{MODEL_NAME}_{TOTAL_FRAMES}frame.json\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_data, f, indent=4, ensure_ascii=False)\n",
    "print(f\"模型输出已保存到: {output_file}\")\n",
    "\n",
    "# 保存评估结果\n",
    "eval_dir = f\"../processed_outputs/real_mc_{PROMPT_TYPE}\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "eval_file = os.path.join(eval_dir, f\"{MODEL_NAME}_{TOTAL_FRAMES}frame.json\")\n",
    "with open(eval_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"评估结果已保存到: {eval_file}\")\n",
    "\n",
    "# 记录准确率\n",
    "log_file = \"../processed_outputs/evaluation_results.txt\"\n",
    "with open(log_file, \"a\") as f:\n",
    "    f.write(f\"\\nEvaluating output directory: {output_dir}\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"Accuracy of {MODEL_NAME}_{TOTAL_FRAMES}frame.json: {accuracy}\\n\")\n",
    "print(f\"准确率已记录到: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 运行 Synthetic 数据集（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取消注释以运行 synthetic 数据集测试\n",
    "\n",
    "# # 准备 synthetic 数据\n",
    "# print(\"准备 Synthetic 数据集...\")\n",
    "# synthetic_messages = prepare_qa_inputs(synthetic_mc_data, TOTAL_FRAMES, prompt_template)\n",
    "# \n",
    "# # 调用 API\n",
    "# print(\"调用 API...\")\n",
    "# synthetic_responses = await generate_from_openai_chat_completion(\n",
    "#     client=client,\n",
    "#     messages=synthetic_messages,\n",
    "#     engine_name=MODEL_NAME,\n",
    "#     temperature=GENERATION_TEMPERATURE,\n",
    "#     max_tokens=MAX_TOKENS,\n",
    "#     top_p=1.0,\n",
    "#     requests_per_minute=requests_per_minute\n",
    "# )\n",
    "# \n",
    "# # 添加响应\n",
    "# for query, response in zip(synthetic_mc_data, synthetic_responses):\n",
    "#     query[\"response\"] = response\n",
    "# \n",
    "# # 评估\n",
    "# print(\"评估中...\")\n",
    "# synthetic_accuracy, synthetic_results = await get_acc_async(synthetic_mc_data, client)\n",
    "# \n",
    "# print(f\"\\nSynthetic 数据集准确率: {synthetic_accuracy:.2%}\")\n",
    "# \n",
    "# # 保存\n",
    "# synth_output_dir = f\"../outputs/synthetic_mc_{PROMPT_TYPE}\"\n",
    "# os.makedirs(synth_output_dir, exist_ok=True)\n",
    "# synth_output_file = os.path.join(synth_output_dir, f\"{MODEL_NAME}_{TOTAL_FRAMES}frame.json\")\n",
    "# with open(synth_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(synthetic_mc_data, f, indent=4, ensure_ascii=False)\n",
    "# print(f\"Synthetic 结果已保存到: {synth_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}